{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c37398-95aa-4ffd-b38a-03a38e310b0c",
   "metadata": {},
   "source": [
    "# Use dot and vectors for weighted ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b022776-d82f-44f7-a106-12c0fd76c451",
   "metadata": {},
   "source": [
    "Table of contents:\n",
    "- Weighted ranking, \"attributes\" only\n",
    "- Weighted ranking, \"attributes+semantic\" in a single pass\n",
    "- Note 1: _what you can and can't do_\n",
    "- Note 2: _an aside on performance_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a155784-f7be-49ad-a68e-87e425809f19",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4121cc08-dd21-41a9-a086-c9af10c8c5f7",
   "metadata": {},
   "source": [
    "Each entry comes with a list of numeric attributes $a_i, i=1...N_{attr}$, which we take to be normalized in the $[0:1]$ interval.\n",
    "\n",
    "We want to be able to query and sort by a \"score function\" $S({a_i}) : \\mathrm{row} \\to \\mathbb{R}$ that is a certain weighted combination of these attributes:\n",
    "$$\n",
    "S(\\mathrm{row}) \\equiv \\sum_{i=1}^N w_i a_i\n",
    "$$\n",
    "\n",
    "We want to lay out a data schema such that different queries, each with arbitrary sets of weights, can all be run on the one table we'll have.\n",
    "\n",
    "Note that the number of \"attributes\" must be known at table-creation time, and their names must be known before inserting any data on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b3e90-13ed-4a6c-bd60-a0cb7835a611",
   "metadata": {},
   "source": [
    "### The principle\n",
    "\n",
    "Let us assume for a moment that the (lowercase) attributes $\\{a_i\\}$ range between zero and one.\n",
    "\n",
    "The formula above for $S(\\mathrm{row})$ is nothing else than the DOT similarity primitive available in Cassandra (modulo a simple transformation that we'll keep into account in a second).\n",
    "\n",
    "**If we store a _vector_ next to each entry, with the attributes collated in a known sequence, we can then ask Cassandra to compute `S` for us and sort results by its descending value**. In other words, at storing time we insert\n",
    "\n",
    "$$\n",
    "v_\\mathrm{row} = [a_1, a_2 ... a_N]\n",
    "$$\n",
    "\n",
    "so that the query with weights $\\{w_i\\}$ can be realized by constructing the query vector\n",
    "\n",
    "$$\n",
    "q = [w_1, w_2, ... w_N]\n",
    "$$\n",
    "\n",
    "Indeed the clause `... ORDER BY vector_column ANN OF q ...` in the `SELECT` will do just that, provided we created the table with the DOT similarity function in the options.\n",
    "\n",
    "**Note**: while it is customarily said that _you should use DOT only when your vectors are guaranteed to be (L2) unit-length_, this whole applications is an example of \"bending the rules\" and exploiting the DOT similarity measure right for what it is even outside of the unit sphere.\n",
    "\n",
    "### Normalization, practicalities\n",
    "\n",
    "If the attributes are already in the $[0:1]$ interval, everything is fine as is. If this is not the case, we distinguish two possibilities:\n",
    "\n",
    "1. the attributes are given as a \"raw\" set of numbers $\\{A_i\\}$, each in its range $[0: A_i^\\mathrm{max}]$ (note the zero!). This is the happy path, as the rescaling $a_i = A_i / A_i^\\mathrm{max}$ can be shifted to the query vector, making it possible to store the $\\{A_i\\}$ on the database and then constructing a modified query vector $\\tilde{q} = \\{w_i / A_i^\\mathrm{max}\\}$. **This is the approach demonstrated in the code**\n",
    "\n",
    "2. The attributes are on a scale that does not start at zero, or even is non-linearly mapped into the unit interval. Examples may be an \"alignment\" value for the fantasy characters (-1 for full evil, +1 for full good), or values $A'_i$ in $[-\\infty: +\\infty]$ that require mappings such as $a_i = 0.5 + \\arctan(k A'_i)/\\pi$ to be tamed into the unit interval. _In those cases it is unavoidable to do some insert-time data preprocessing_, something not shown here.\n",
    "\n",
    "### Cassandra similarity and the actual score\n",
    "\n",
    "Using the $\\{q_i\\}$ with the $\\{a_i\\}$ (or equivalently the $\\{\\tilde{q}_i\\}$ with the $\\{A_i\\}$), we have the guarantee that the \"theoretical maximum score\" (when all attributes assume their maximum value) is one (Also the minimum is trivially zero), a fact that may come handy. And CQL makes it easy to get the similarity itself back from an ANN query, by adding something like `... similarity_dot_product(vector_column, q) as score ...`.\n",
    "\n",
    "**But beware!**, for the DOT similarity in Cassandra was built with the \"shortcut-for-cosine\" use case, and a nice $[0:1]$ normalization, in mind.\n",
    "\n",
    "As a consequence, the DOT similarity in Cassandra does not return exactly $S = \\vec{q} \\cdot \\vec{a}$, rather\n",
    "\n",
    "$$\n",
    "\\mathrm{sim}_\\mathrm{Cass} = \\frac{1 + \\vec{q} \\cdot \\vec{a}}{2}\n",
    "$$\n",
    "\n",
    "This means that, if we are interested in the _value_ of the returned similarities, we should counter the above rescaling by applying $S = 2 \\; \\mathrm{sim}_\\mathrm{Cass} - 1$ after running the CQL query.\n",
    "\n",
    "_Related:_ in this notebook, unless specified otherwise, \"cosine similarity\" denotes the quantity scaled to lie in $[-1: +1]$ (and not the Cassandra rescaling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e212b56-7e17-4990-b1ac-bb48b4671075",
   "metadata": {},
   "source": [
    "### Sample data\n",
    "\n",
    "Here we take all the ability scores to always lie in 0-10:\n",
    "\n",
    "```\n",
    "Strength      measuring physical power\n",
    "Dexterity,    measuring agility\n",
    "Constitution, measuring endurance\n",
    "Intelligence  measuring reasoning and memory\n",
    "Wisdom        measuring perception and insight\n",
    "Charisma      measuring force of personality\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ef9b539-a41a-4eae-b5ef-26e33cd38a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ABILITY_VALUES = [10, 10, 10, 10, 10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf88f31-1504-4d80-a02e-0c42df654e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters0 = [\n",
    "    {\n",
    "        \"name\": \"Gondolf\",\n",
    "        \"description\": \"A wizard with long nose and a sardonic smile\",\n",
    "        \"abilities_map\": {\n",
    "            \"CHA\": 8,\n",
    "            \"CON\": 3,\n",
    "            \"DEX\": 5,\n",
    "            \"INT\": 10,\n",
    "            \"STR\": 4,\n",
    "            \"WIS\": 9,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Bargul\",\n",
    "        \"description\": \"A mighty brute, able to smash rocks with his forehead.\",\n",
    "        \"abilities_map\": {\n",
    "            \"CHA\": 3,\n",
    "            \"CON\": 9,\n",
    "            \"DEX\": 4,\n",
    "            \"INT\": 2,\n",
    "            \"STR\": 10,\n",
    "            \"WIS\": 3,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Zittur\",\n",
    "        \"description\": \"A lightweight fairy, capable of slipping in unseen and making herself unnoticed.\",\n",
    "        \"abilities_map\": {\n",
    "            \"CHA\": 9,\n",
    "            \"CON\": 4,\n",
    "            \"DEX\": 9,\n",
    "            \"INT\": 7,\n",
    "            \"STR\": 3,\n",
    "            \"WIS\": 5,\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceebbe0-ab18-4e1c-94d3-522994652585",
   "metadata": {},
   "source": [
    "### Setup & Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1188d64c-12d1-4f87-a1c7-9c56c82163f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cassio>=0.1.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12883bcb-72cf-4871-ab2b-e5096f057e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import cassio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b11daca-5d4f-4afc-895f-f6417d68bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ASTRA_DB_ID' not in os.environ:\n",
    "    os.environ[\"ASTRA_DB_ID\"] = input(\"ASTRA_DB_ID = \")\n",
    "\n",
    "if 'ASTRA_DB_APPLICATION_TOKEN' not in os.environ:\n",
    "    os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"] = getpass(\"ASTRA_DB_APPLICATION_TOKEN = \")\n",
    "\n",
    "if 'ASTRA_DB_KEYSPACE' not in os.environ:\n",
    "    ks = input(\"(Optional) ASTRA_DB_KEYSPACE = \")\n",
    "    if ks:\n",
    "        os.environ[\"ASTRA_DB_KEYSPACE\"] = ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b8bb0d-0667-4415-a1d3-5d3831aba2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cassio.init(\n",
    "    database_id=os.environ[\"ASTRA_DB_ID\"],\n",
    "    token=os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"],\n",
    "    keyspace=os.environ.get(\"ASTRA_DB_KEYSPACE\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4b49d0-ba69-49e3-ba0d-9777201027b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "session, keyspace = cassio.config.resolve_session(), cassio.config.resolve_keyspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76fd470-d7cb-4b3b-b094-b0193dd6022d",
   "metadata": {},
   "source": [
    "## Weighted ranking, attributes-only case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6c530f-5901-4235-a502-10a6e3fea179",
   "metadata": {},
   "source": [
    "### Create vector table\n",
    "\n",
    "This is where we need to know the number of abilities (six in our example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb5480b-e8b1-4ed4-836e-212f9db8c219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f6bf37554c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREATE_TABLE_STATEMENT = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {keyspace}.fantasy_simple (\n",
    "    name TEXT PRIMARY KEY,\n",
    "    description TEXT,\n",
    "    abilities VECTOR<FLOAT, 6>,\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "session.execute(CREATE_TABLE_STATEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87da7ba9-841c-4041-9892-754bf493baee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f6c30482580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREATE_INDEX_STATEMENT = f\"\"\"\n",
    "CREATE CUSTOM INDEX IF NOT EXISTS idx_abilities\n",
    "    ON {keyspace}.fantasy_simple (abilities)\n",
    "    USING 'org.apache.cassandra.index.sai.StorageAttachedIndex'\n",
    "    WITH OPTIONS = {{'similarity_function' : 'dot_product'}};\n",
    "\"\"\"\n",
    "# Note: the double '{{' and '}}' are just the F-string escape sequence for '{' and '}'\n",
    "\n",
    "session.execute(CREATE_INDEX_STATEMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3338a8-c4bb-43d4-b97d-9bd6c6690e9c",
   "metadata": {},
   "source": [
    "### Write data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0758d7-aaed-49bb-9a73-08bf5eb98148",
   "metadata": {},
   "source": [
    "This is where we need to nail down a fixed ordering of the attributes in a list to match stored and query vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349c8a9c-ab17-47dd-a2d9-4b9222e6ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a global, unambiguous ordering scheme\n",
    "ABILITY_LIST = [\"CHA\", \"CON\", \"DEX\", \"INT\", \"STR\", \"WIS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a6d0b-ecfb-47e8-a700-8e00daa25f2e",
   "metadata": {},
   "source": [
    "Useful conversion utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1f30d8-e477-447d-b57b-c79f6cddfd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Bargul: [3, 9, 4, 2, 10, 3]\n",
      "=> {'CHA': 1, 'CON': 2, 'DEX': 3, 'INT': 4, 'STR': 5, 'WIS': 6}\n"
     ]
    }
   ],
   "source": [
    "def abilities_to_vector(a_dict):\n",
    "    return [a_dict[ability] for ability in ABILITY_LIST]\n",
    "\n",
    "def abilities_to_map(a_vector):\n",
    "    return {\n",
    "        ability_key: ability_value\n",
    "        for ability_key, ability_value in zip(ABILITY_LIST, a_vector)\n",
    "    }\n",
    "\n",
    "print(f\"=> {characters0[1]['name']}: {abilities_to_vector(characters0[1]['abilities_map'])}\")\n",
    "print(f\"=> {abilities_to_map([1, 2, 3, 4, 5, 6])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "877e58c1-97e1-4ffb-9508-c337964c761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT_STATEMENT = session.prepare(f\"\"\"\n",
    "    INSERT INTO {keyspace}.fantasy_simple\n",
    "        (name, description, abilities)\n",
    "    VALUES\n",
    "        (?,?,?);\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "for character in characters0:\n",
    "    session.execute(\n",
    "        INSERT_STATEMENT,\n",
    "        (\n",
    "            character[\"name\"],\n",
    "            character[\"description\"],\n",
    "            abilities_to_vector(character[\"abilities_map\"]),\n",
    "        ),\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6cf7f6-c23a-474d-8e31-e056938b9bb4",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77c0a879-e8f0-4761-84de-de74501448fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_STATEMENT = session.prepare(f\"\"\"\n",
    "    SELECT name, description, abilities, similarity_dot_product(abilities, ?) as score\n",
    "        FROM {keyspace}.fantasy_simple\n",
    "        ORDER BY abilities ANN OF ?\n",
    "        LIMIT ?;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def find_best_matches(ability_weight_map, n = 1):\n",
    "    \"\"\"\n",
    "    the theoretical max score from this query is the sum of the weights.\n",
    "    \"\"\"\n",
    "    # make requested weights into vector\n",
    "    query_vector0 = abilities_to_vector(ability_weight_map)\n",
    "    # ensure each of its component encodes the inverse rescaling for the DB values\n",
    "    query_vector = [x0 / max_val for x0, max_val in zip(query_vector0, MAX_ABILITY_VALUES)]\n",
    "    # run the proper search\n",
    "    results = session.execute(\n",
    "        QUERY_STATEMENT,\n",
    "        (\n",
    "            query_vector,\n",
    "            # again, to match the '?' in the statement:\n",
    "            query_vector,\n",
    "            n,\n",
    "        ),\n",
    "    )\n",
    "    return [\n",
    "        {\n",
    "            \"name\": row.name,\n",
    "            \"description\": row.description,\n",
    "            \"abilities_map\": abilities_to_map(row.abilities),\n",
    "            \"score\": 2 * row.score - 1,  # remember Cassandra rescales the dot in its similarities\n",
    "        }\n",
    "        for row in results\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6de9f4c7-a450-4e52-b516-fb7bb6645728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Bargul',\n",
       "  'description': 'A mighty brute, able to smash rocks with his forehead.',\n",
       "  'abilities_map': {'CHA': 3.0,\n",
       "   'CON': 9.0,\n",
       "   'DEX': 4.0,\n",
       "   'INT': 2.0,\n",
       "   'STR': 10.0,\n",
       "   'WIS': 3.0},\n",
       "  'score': 0.7100000381469727}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_matches({\"CHA\": 0.1, \"CON\": 0.1, \"DEX\": 0.1, \"INT\": 0.1, \"STR\": 0.5, \"WIS\": 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c59d79-010c-4f68-bf74-3173487ceec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Zittur',\n",
       "  'description': 'A lightweight fairy, capable of slipping in unseen and making herself unnoticed.',\n",
       "  'abilities_map': {'CHA': 9.0,\n",
       "   'CON': 4.0,\n",
       "   'DEX': 9.0,\n",
       "   'INT': 7.0,\n",
       "   'STR': 3.0,\n",
       "   'WIS': 5.0},\n",
       "  'score': 0.7300000190734863},\n",
       " {'name': 'Gondolf',\n",
       "  'description': 'A wizard with long nose and a sardonic smile',\n",
       "  'abilities_map': {'CHA': 8.0,\n",
       "   'CON': 3.0,\n",
       "   'DEX': 5.0,\n",
       "   'INT': 10.0,\n",
       "   'STR': 4.0,\n",
       "   'WIS': 9.0},\n",
       "  'score': 0.5899999141693115}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_matches({\"CHA\": 0.1, \"CON\": 0.1, \"DEX\": 0.5, \"INT\": 0.1, \"STR\": 0.1, \"WIS\": 0.1}, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb6aea76-a2e7-435d-b9d5-67f43850dfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Gondolf',\n",
       "  'description': 'A wizard with long nose and a sardonic smile',\n",
       "  'abilities_map': {'CHA': 8.0,\n",
       "   'CON': 3.0,\n",
       "   'DEX': 5.0,\n",
       "   'INT': 10.0,\n",
       "   'STR': 4.0,\n",
       "   'WIS': 9.0},\n",
       "  'score': 0.6699999570846558}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_matches({\"CHA\": 0.1, \"CON\": 0.1, \"DEX\": 0.1, \"INT\": 0.3, \"STR\": 0.3, \"WIS\": 0.1}, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1d5d2-6a69-40d7-b3ab-5cba2914f314",
   "metadata": {},
   "source": [
    "#### Sort by a single attribute\n",
    "\n",
    "Note that the above machinery trivially contains a sub-use-case that is useful in its own right: sorting results by _exactly one attribute_. It is sufficient to pass a weight set that is effectively a \"Kronecker delta\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83c9fc57-4b8b-415c-a032-b680f2bdef8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Zittur',\n",
       "  'description': 'A lightweight fairy, capable of slipping in unseen and making herself unnoticed.',\n",
       "  'abilities_map': {'CHA': 9.0,\n",
       "   'CON': 4.0,\n",
       "   'DEX': 9.0,\n",
       "   'INT': 7.0,\n",
       "   'STR': 3.0,\n",
       "   'WIS': 5.0},\n",
       "  'score': 0.9000000953674316},\n",
       " {'name': 'Gondolf',\n",
       "  'description': 'A wizard with long nose and a sardonic smile',\n",
       "  'abilities_map': {'CHA': 8.0,\n",
       "   'CON': 3.0,\n",
       "   'DEX': 5.0,\n",
       "   'INT': 10.0,\n",
       "   'STR': 4.0,\n",
       "   'WIS': 9.0},\n",
       "  'score': 0.5},\n",
       " {'name': 'Bargul',\n",
       "  'description': 'A mighty brute, able to smash rocks with his forehead.',\n",
       "  'abilities_map': {'CHA': 3.0,\n",
       "   'CON': 9.0,\n",
       "   'DEX': 4.0,\n",
       "   'INT': 2.0,\n",
       "   'STR': 10.0,\n",
       "   'WIS': 3.0},\n",
       "  'score': 0.3999999761581421}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_matches({\"CHA\": 0.0, \"CON\": 0.0, \"DEX\": 1.0, \"INT\": 0.0, \"STR\": 0.0, \"WIS\": 0.0}, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f1cb9f-78c1-4c17-a6f2-0411fe50d7df",
   "metadata": {},
   "source": [
    "#### Normalizations check\n",
    "\n",
    "Just as a sanity check for the normalizations, we'll insert two more characters in the story:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66aa53ef-a080-457c-988e-9831e6fd2c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f6bf37819d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\n",
    "    INSERT_STATEMENT,\n",
    "    (\"Cthulhu\", \"An almighty ancient god\", [10] * 6)\n",
    ")\n",
    "session.execute(\n",
    "    INSERT_STATEMENT,\n",
    "    (\"Puny Terry\", \"Terry no strong, Terry no smart\", [0] * 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f63af-457d-4ba2-a5d3-76b9c9aa137e",
   "metadata": {},
   "source": [
    "Let's try a couple of queries (ensuring the input weights sum to one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f802a0b2-acc3-44b6-a843-c384bb839704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.6449999809265137\n",
      "0.565000057220459\n",
      "0.5499999523162842\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "query1 = abilities_to_map([0.05, 0.1, 0.15, 0.2, 0.3, 0.2])\n",
    "for result in find_best_matches(query1, n=100):\n",
    "    print(result[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b21f9af-64a2-4cf0-b73f-6c12e7922e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999998807907104\n",
      "0.7599999904632568\n",
      "0.5\n",
      "0.440000057220459\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "query1 = abilities_to_map([0.0, 0.4, 0.2, 0.1, 0.3, 0.0])\n",
    "for result in find_best_matches(query1, n=100):\n",
    "    print(result[\"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb21d1-cb65-4aa4-b1c9-3c42020e4413",
   "metadata": {},
   "source": [
    "If you don't care about the _value_ of the resulting scores, you can even use negative weights (and forget about sum-to-one weights) to make some attributes into a **penalty**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f78e2ba2-8a78-4aea-afb3-6a291f156d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bargul: 1.9000000953674316\n",
      "Cthulhu: 1.5\n",
      "Zittur: 0.8500001430511475\n"
     ]
    }
   ],
   "source": [
    "# We don't like smartasses around here ...\n",
    "for result in find_best_matches({'CHA': 1, 'CON': 1, 'DEX': 0.5, 'INT': -1.0, 'STR': 1.0, 'WIS': -1.0}, n=3):\n",
    "    print(f\"{result['name']}: {result['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e06cd-b27b-4e3d-9824-d693d7353e6e",
   "metadata": {},
   "source": [
    "## Weighted ranking, attributes+semantic in a single pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1948581-d029-432d-b0c4-ca1d011692b0",
   "metadata": {},
   "source": [
    "We now turn to the next problem: we want to mix _semantic search_ with the above criterion. And we need it to work in a _single pass_, i.e. with just one database query.\n",
    "\n",
    "More precisely, with $S$ the attribute-based score as seen in the previous section, we need to sort rows based on the composite \"attributes+semantic\" score:\n",
    "\n",
    "$$\n",
    "S^\\star = \\lambda T + (1-\\lambda) S\n",
    "$$\n",
    "\n",
    "where $T$ is the \"semantic similarity\" between a query text and the text on the stored row, calculated as the cosine similarity between the embedding vectors (of dimension $M$), and $\\lambda$ is a parameter in $[0:1]$ tuned in the application and/or supplied with each query along with the weights. The \"query\" $Q$ then is defined by three things:\n",
    "- the weights $\\{w_i\\}$ for $S$;\n",
    "- a text $t_q$ for the semantic-similarity part of the query;\n",
    "- a real value $\\lambda$ specifying how to mix these two (one for full-semantic, zero for full-attribute-based).\n",
    "\n",
    "**Note**: in the following, we require that the _embedding vectors have unit L2 norm_ (it will be care of the implementation to ensure this is the case if the embedding service does not satisfy). This allows replacing the cosine similarity with the dot product as far as the semantic part of the score is concerned: calling $\\mathrm{emb}(t)$ the embedding vector for the text $t$, we have:\n",
    "\n",
    "$$\n",
    "S^\\star(Q, \\mathrm{row}) = \\lambda T(t_q, t_\\mathrm{row}) + (1-\\lambda) S(\\vec{w}, \\vec{a}) = \\ldots\n",
    "$$\n",
    "\n",
    "i.e.\n",
    "\n",
    "$$\n",
    "\\ldots = \\lambda \\mathrm{emb}(t_q) \\cdot \\mathrm{emb}(t_\\mathrm{row}) + (1-\\lambda)\\vec{w}\\cdot\\vec{a} = \\ldots\n",
    "$$\n",
    "\n",
    "meaning\n",
    "\n",
    "$$\n",
    "\\ldots = [\\lambda \\mathrm{emb}(t_q) ] \\cdot \\mathrm{emb}(t_\\mathrm{row}) + [(1-\\lambda)\\vec{w}] \\cdot\\vec{a}\n",
    "$$\n",
    "\n",
    "Now it is clear that we can construct a \"composite row vector\" by _collating the text embedding and the attributes_ and store it in the database table:\n",
    "\n",
    "$$\n",
    "\\vec{v}^\\star(\\mathrm{row}) \\equiv [\\mathrm{emb}(t_\\mathrm{row}); a_i]\n",
    "$$\n",
    "\n",
    "and construct a \"composite query vector\" at query time, likewise of dimension $M+N$ , like this:\n",
    "\n",
    "$$\n",
    "\\vec{q}^\\star = [\\lambda \\mathrm{emb}(t_q) ; (1-\\lambda) w_i ]\n",
    "$$\n",
    "\n",
    "In this way, queries can rank and return results effectively sorted by descending value of\n",
    "\n",
    "$$\n",
    "\\vec{q}^\\star \\cdot \\vec{v}^\\star = S^\\star(Q, \\mathrm{row})\n",
    "$$\n",
    "\n",
    "The same remarks done for the \"attributes-only\" case apply here, about rescaling the \"similarity\" back from the Cassandra-specific transformation and replacing $w_i$ with $w_i / A_i^\\mathrm{max}$ if needed.\n",
    "\n",
    "_Corollary_ of the above derivation: the \"theoretical\" maximum score one can obtain, assuming the text embeddings have unit norm, is $\\lambda + (1-\\lambda)\\sum w_i$, and the minimum is $-\\lambda$. _(The latter will be never attained in practice, given that text embeddings even for totally unrelated/gibberish input texts, seldom have negative similarities.)_\n",
    "\n",
    "**Let's see this plan in action.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e377d0a9-5b93-4e58-94db-776236552fbb",
   "metadata": {},
   "source": [
    "### Text embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386fea3-bb28-4e4a-876d-19bd56ad01bb",
   "metadata": {},
   "source": [
    "Pick OpenAI's embedding (but we could use any text embedding, of course. You can replace the definition of `embed` to your tastes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8460c9ec-41ce-4662-a329-de0e307cf0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"openai>=1.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33de37a0-6c33-4d10-b073-7e56cfead4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"OPENAI_API_KEY = \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9878fc0-513c-4de0-bb42-5bbacfb333cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "def embed(text):\n",
    "    return client.embeddings.create(input=[text], model=\"text-embedding-ada-002\").data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c2df612-f3bd-42ca-b2dd-ff06a3fe78d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension M = 1536\n"
     ]
    }
   ],
   "source": [
    "M = len(embed(\"Just to check the length\"))\n",
    "print(f\"Dimension M = {M}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff6eab-e25f-4676-a47e-06567bf8d248",
   "metadata": {},
   "source": [
    "#### Create table and index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7029d9-33ea-4f85-9955-aeb61d06badd",
   "metadata": {},
   "source": [
    "Note that we add an `abilities_map` map field. Not strictly necessary but we'd rather avoid reconstructing the ability map from the returned rows by isolating the $N$ last components of the composite vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e08ce2c-55bb-4221-be57-afb8928abaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f6c304846a0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREATE_TABLE_STATEMENT_C = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {keyspace}.fantasy_composite (\n",
    "    name TEXT PRIMARY KEY,\n",
    "    description TEXT,\n",
    "    abilities_map MAP<TEXT, FLOAT>,\n",
    "    composite VECTOR<FLOAT, {6 + M}>,\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "session.execute(CREATE_TABLE_STATEMENT_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da9eceab-eb25-48c5-a722-573a1fbf7948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f6c09747760>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREATE_INDEX_STATEMENT_C = f\"\"\"\n",
    "CREATE CUSTOM INDEX IF NOT EXISTS idx_abilities_composite\n",
    "    ON {keyspace}.fantasy_composite (composite)\n",
    "    USING 'org.apache.cassandra.index.sai.StorageAttachedIndex'\n",
    "    WITH OPTIONS = {{'similarity_function' : 'dot_product'}};\n",
    "\"\"\"\n",
    "\n",
    "session.execute(CREATE_INDEX_STATEMENT_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea3879c-fdc3-459d-9f32-7f716185a7cd",
   "metadata": {},
   "source": [
    "### Insert data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732bd4a1-8fba-45d8-af1c-0f8f05b9ab1a",
   "metadata": {},
   "source": [
    "Let's introduce two new characters, differing from the wizard just in the (name, and) description field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fb0c7b5-874b-471b-8f95-8a3662a62e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters1 = characters0 + [\n",
    "    {\n",
    "        \"name\": \"Argold\",\n",
    "        \"description\": \"A powerful, quiet mage with a penchant for gardening and cooking.\",\n",
    "        \"abilities_map\": {\n",
    "            \"CHA\": 8,\n",
    "            \"CON\": 3,\n",
    "            \"DEX\": 5,\n",
    "            \"INT\": 10,\n",
    "            \"STR\": 4,\n",
    "            \"WIS\": 9,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Sabiria\",\n",
    "        \"description\": \"This ruthless witch cooks you alive first, and asks questions later.\",\n",
    "        \"abilities_map\": {\n",
    "            \"CHA\": 8,\n",
    "            \"CON\": 3,\n",
    "            \"DEX\": 5,\n",
    "            \"INT\": 10,\n",
    "            \"STR\": 4,\n",
    "            \"WIS\": 9,\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62ce305d-0711-45dc-a8dd-a1d01d863052",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT_STATEMENT = session.prepare(f\"\"\"\n",
    "    INSERT INTO {keyspace}.fantasy_composite\n",
    "        (name, description, abilities_map, composite)\n",
    "    VALUES\n",
    "        (?,?,?, ?);\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "for character in characters1:\n",
    "    session.execute(\n",
    "        INSERT_STATEMENT,\n",
    "        (\n",
    "            character[\"name\"],\n",
    "            character[\"description\"],\n",
    "            character[\"abilities_map\"],\n",
    "            # here the composite vector is constructed:\n",
    "            embed(character[\"description\"]) + abilities_to_vector(character[\"abilities_map\"])\n",
    "        ),\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6319d42-fd28-45eb-bf70-d6d05fdbd15b",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d5d52db-0702-49b2-b3f1-47bb2c11ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_STATEMENT_C = session.prepare(f\"\"\"\n",
    "    SELECT name, description, abilities_map, similarity_dot_product(composite, ?) as score\n",
    "        FROM {keyspace}.fantasy_composite\n",
    "        ORDER BY composite ANN OF ?\n",
    "        LIMIT ?;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def find_best_matches_composite(query_text, ability_weight_map, param_lambda=0.5, n = 1):\n",
    "    \"\"\"\n",
    "    the theoretical max score from this query is:\n",
    "        lambda + (1-lambda) * (the sum of the weights)\n",
    "    the minimum is\n",
    "        -lambda\n",
    "    \"\"\"\n",
    "    # the \"ability\" part:\n",
    "    ability_q_vector0 = abilities_to_vector(ability_weight_map)\n",
    "    ability_q_vector = [x0 / max_val for x0, max_val in zip(ability_q_vector0, MAX_ABILITY_VALUES)]\n",
    "    # the \"text\" part:\n",
    "    text_q_vector = embed(query_text)\n",
    "    # combining the two\n",
    "    query_vector = [\n",
    "        param_lambda * emb_x\n",
    "        for emb_x in text_q_vector\n",
    "    ] + [\n",
    "        (1 - param_lambda) * abi_x\n",
    "        for abi_x in ability_q_vector\n",
    "    ]\n",
    "    \n",
    "    # run the proper search\n",
    "    results = session.execute(\n",
    "        QUERY_STATEMENT_C,\n",
    "        (\n",
    "            query_vector,\n",
    "            # again, to match the '?' in the statement:\n",
    "            query_vector,\n",
    "            n,\n",
    "        ),\n",
    "    )\n",
    "    return [\n",
    "        {\n",
    "            \"name\": row.name,\n",
    "            \"description\": row.description,\n",
    "            \"abilities_map\": row.abilities_map,\n",
    "            \"score\": 2 * row.score - 1,  # remember Cassandra rescales the dot in its similarities\n",
    "        }\n",
    "        for row in results\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f792c2c-e2be-419e-843b-e400e0bcc7f8",
   "metadata": {},
   "source": [
    "A printing tool to make output shorter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eff6e550-f89a-4687-9c79-fdcd3d29581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_show(*pargs, **kwargs):\n",
    "    for res in find_best_matches_composite(*pargs, **kwargs):\n",
    "        print(f\"* {res['name']:<16s} ({res['score']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d825f-c20e-4d37-83fc-365b193b6ca6",
   "metadata": {},
   "source": [
    "#### Run some queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c834e9-c59a-42f7-b6f7-61a98e658188",
   "metadata": {},
   "source": [
    "The two cells below will pick \"magic characters\" by attributes, and the semantic part will do the fine part of the ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "272ba81f-982f-4e8f-aa46-cb3e880423e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sabiria          (0.7360055446624756)\n",
      "* Gondolf          (0.7342482805252075)\n",
      "* Argold           (0.7205580472946167)\n"
     ]
    }
   ],
   "source": [
    "search_and_show(\n",
    "    \"Looking for someone definitely evil.\",\n",
    "    {\"CHA\": 0.1, \"CON\": 0.1, \"DEX\": 0.1, \"INT\": 0.3, \"STR\": 0.3, \"WIS\": 0.1},\n",
    "    param_lambda=0.8,\n",
    "    n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d2026426-cb6f-4187-b938-634eef58694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sabiria          (0.6964023113250732)\n",
      "* Gondolf          (0.6956992149353027)\n",
      "* Argold           (0.690223217010498)\n"
     ]
    }
   ],
   "source": [
    "search_and_show(\n",
    "    \"Looking for someone definitely evil.\",\n",
    "    {\"CHA\": 0.1, \"CON\": 0.1, \"DEX\": 0.1, \"INT\": 0.3, \"STR\": 0.3, \"WIS\": 0.1},\n",
    "    param_lambda=0.2,\n",
    "    n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5930b02-e3de-4b26-a181-f6d4dd9a6baf",
   "metadata": {},
   "source": [
    "The difference is $\\lambda$, which has a _slight_ effect on the final scores. Why such a small effect?\n",
    "\n",
    "Well, even if vectors' cosine similarity can span the whole $[-1,+1]$ range, as a matter of fact text embeddings always fall on a thin \"cone\" in vector space, such that their cosine similarity is generally between 0.5 and 1 if not in a narrower window. This important practical fact, perhaps paired with an investigation into the exact nature of the data at hand and the embeddings used, may warrant adaptations of the above flow to take this into account. **This is a very important point not to underestimate for the quality of the final outcomes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a351771-87df-4751-ba3c-3a45883f6d26",
   "metadata": {},
   "source": [
    "#### Pure similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e8f1343-fe02-4e9c-9242-189257bb8f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Argold           (0.8322060108184814)\n",
      "* Zittur           (0.8034632205963135)\n",
      "* Gondolf          (0.7896300554275513)\n"
     ]
    }
   ],
   "source": [
    "search_and_show(\n",
    "    \"This one loves a quiet life\",\n",
    "    {\"CHA\": 0, \"CON\": 0, \"DEX\": 0, \"INT\": 0, \"STR\": 0, \"WIS\": 0},\n",
    "    param_lambda=1,\n",
    "    n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c765d5-3dd7-4b23-b89f-034582cf2a03",
   "metadata": {},
   "source": [
    "#### Pure attribute-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "90e48442-b855-4c55-aca0-6832d5861dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Bargul           (0.7999999523162842)\n",
      "* Zittur           (0.5)\n",
      "* Argold           (0.4099999666213989)\n"
     ]
    }
   ],
   "source": [
    "search_and_show(\n",
    "    \"(this sentence will have no effect since lambda=0)\",\n",
    "    {\"CHA\": 0, \"CON\": 0.2, \"DEX\": 0.3, \"INT\": 0.0, \"STR\": 0.5, \"WIS\": 0.0},\n",
    "    param_lambda=0,\n",
    "    n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46636a53-d46d-4934-bbff-d595aff82930",
   "metadata": {},
   "source": [
    "## Limitations of this approach, workarounds\n",
    "\n",
    "Applying a _threshold_ on similarity and, within the passing entries, sort by the composite score is probably impossible in a single pass.\n",
    "\n",
    "Anything involving nonlinear transformations of the original scores/dot-based similarity is likely to be painful and/or impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b785670-e522-45dd-a250-af001f54b2d5",
   "metadata": {},
   "source": [
    "### Semantic adjustments, an example\n",
    "\n",
    "On the other hand, let's see how a \"fix\" for the problem of the \"semantic narrow window\" could look like.\n",
    "\n",
    "Suppose we want to adopt a \"cut and stretched\" form of the semantic similarity, $\\tau = 5(T-0.8)$, after having found that $T \\in [0.8:1]$ in _all_ cases: then we're after a modified\n",
    "\n",
    "$$\n",
    "S'^\\star = \\lambda \\tau + (1-\\lambda) S = 5\\lambda T + (1-\\lambda) S - 0.8\\lambda\n",
    "$$\n",
    "\n",
    "The last term is a constant for a given query and we can drop it as far as the results ranking is concerned.\n",
    "We can also divide the score by any positive constant (we are only interested in getting the results in a certain order at the moment).\n",
    "\n",
    "So we are left with something that has the same shape as the \"regular\" care, under a renaming of the $\\lambda$ parameter: with $\\lambda' = 5\\lambda / (4\\lambda+1)$, it is:\n",
    "\n",
    "$$\n",
    "S'^\\star(\\lambda) \\propto \\left(\\frac{5\\lambda}{4\\lambda+1}\\right)T + \\left(\\frac{1-\\lambda}{4\\lambda+1}\\right)S = \\lambda' T + (1-\\lambda') S = S^\\star(\\lambda')\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2184d68-f3a4-48e7-a896-4fb1c9795563",
   "metadata": {},
   "source": [
    "## Performance considerations\n",
    "\n",
    "Departing from the comfort zone of using the DOT measure on the unit sphere, just as a faster form of the cosine similarity, comes with a performance issue that should be kept in mind.\n",
    "\n",
    "The DOT measure is a \"strange beast\". It does not behave like a reasonable measure of \"how close\" two \"things\" are. The following (informal) expecation, while reasonable and in fact satisfied by both euclidean and cosine, **fails** for DOT:\n",
    "> Given that \"A is close to B\" and \"B is far from C\", you should be able to expect that \"A is far from C\"\n",
    "\n",
    "Here's a DOT counterexample, where one takes \"close/far\" to mean \"DOT is ~1 / ~0\"\n",
    "\n",
    "![dot](https://user-images.githubusercontent.com/14221764/284030947-30738034-f1a9-4760-9b4d-bb2a1c3009f4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19408ce3-b345-4495-bf68-3c1e5e0316e5",
   "metadata": {},
   "source": [
    "In other words, DOT is tricky because it looks at \"shadows on a wall\": things may seem very close if a certain light is turned on, but switch to the other light, look at the shadow on the other wall and suddenly the objects turn out to be not close at all.\n",
    "\n",
    "Since \"switching light source\" stands for \"changing the query vector\", in DOT-land there is no way to build a single HNSW index ready to work efficiently with all query vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66b681b-8836-4536-8575-effc728aa821",
   "metadata": {},
   "source": [
    "The performance of DOT with non-unit-norm vectors has not been the target of any specific optimization, and by all expectations there will be less stellar results that on the happy paths, especially when the data size starts to be massive. (response times, possibly degrade recall?)\n",
    "\n",
    "_It could be advisable to explore this in a systematic way._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
