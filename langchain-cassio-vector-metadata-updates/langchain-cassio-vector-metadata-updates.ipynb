{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85b4058-272a-4f97-8e06-8b5d57f8ff71",
   "metadata": {},
   "source": [
    "# Update metadata on LangChain/CassIO vector stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2f022-b41d-4f53-af06-ca6d77eda54e",
   "metadata": {},
   "source": [
    "_2023-12-02_\n",
    "\n",
    "Problem: you want to update the metadata for existing vector-store rows on a LangChain `Cassandra` store\n",
    "\n",
    "- without re-computing the vector embeddings, rather leaving them as they are on DB already\n",
    "- ideally not breaking out of the LC abstraction level (we'll see to which extent this goal is possible)\n",
    "- we'll aim at a flow whose inputs are `(doc_id, new_metadata_dict)`, i.e. we assume _you start by knowing the ID of the document to start with_\n",
    "\n",
    "Now there are various possible approaches here, depending on several factors:\n",
    "\n",
    "- you may prefer whole-row inserts or just-metadata (partial) writes\n",
    "- for whole-row, you may not have the text/vector values handy and might need read-before-write\n",
    "- you may have no qualm jumping out of LangChain abstractions (i.e. working at CassIO) or prefer to stray out of LangChain as little as possible\n",
    "\n",
    "Some of the above depends on the needs and the flow of your app, but there's more. You should at least consider the above options because:\n",
    "\n",
    "- currently (as of 2023-12-02) the best performance in subsequent ANN comes from just-metadata (\"partial\") writes, but there are optimizations being explored that promise even better performance under the conditions of whole-row updates. This may make a read-before-write a fair price to pay (depending possibly on the exact usage patterns)\n",
    "- the more you jump out of LangChain, the higher the chances that you will have to do a bit of maintenance to the solution whenever the engine powering LangChain's `Cassandra` store is upgraded. There is a major LC code improvement coming (support for partitioning among other things) whose implications on this task will require a small change in this solution's code (a trivial change amounting to replacing `updater_store.table.table` with `updater_store.table`, but to keep in mind).\n",
    "- Conversely, staying on the LangChain layer (as you'll see, this is more like \"staying on it as far as possible\") comes with its challenges since LangChain constrains somewhat what you can do. LangChain \"vector store\" abstract class has no \"get row by ID\" primitive, for instance, nor does it offer a native \"store this vector+text+metadata\" method (!). These two shortcomings require some detours if the goal is to really stay within the LangChain layer as much as possible.\n",
    "- I would strongly discourage working at the CQL level. There's no need for it that I can think of, plus there's a danger related to how CassIO transforms your `metadata` dicts into the actual table contents. (not going to details here, but your life is easier if you don't go below CassIO. I can elaborate more on this point if you're curious)\n",
    "\n",
    "Note: this study looks at **single- or few-rows updates** here. For a bulk update operation, other techniques are in order (dsbulk + custom dumpfile transformations, Spark, or similar). By \"few rows\" we mean up to ~hundreds or so, whose list of IDs could have been obtained in various ways (see later).\n",
    "\n",
    "Note also that the metadata dictionary is updated as a whole, i.e. all of the previous content is replaced by the new (including old fields that disappear if not provided in the new metadata dictionary). No field-by-field updates (to have that, you will modify the read-before-writes paths demonstrated here to achieve that).\n",
    "\n",
    "Here we'll look at several options, but keep this in mind: **Staying at the LC layer is more pain than gain, I kept the first two options for reference, but move them to the end of the notebook. Feel free to focus on options 3 and 4 and keep 5 in mind for the future**.\n",
    "\n",
    "1. _Whole-row write + stay (mostly) on LC + know whole row already_ (skip if not interested)\n",
    "2. _Whole-row write + stay (mostly) on LC + need to read text&vector beforehand_ (skip if not interested)\n",
    "3. Whole-row write + work at CassIO level + need to read text&vector beforehand\n",
    "4. Partial write + work at CassIO level\n",
    "5. Partial write + work at CassIO/LC level (to be implemented, just outlining the idea here)\n",
    "\n",
    "**TL;DR** = I would go for 3 or 4 (depending what the SAI engineers say is best for performance now and a few weeks in the future), keeping an eye on 5 which will be added just to write fewer lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc66fe86-8b6d-4a9a-94c1-9bbfe58e23bf",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37bdc955-bc21-4393-85d1-3d50f0888cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q \"langchain>=0.0.341\" \"cassio>=0.1.3\" \"openai~=1.3.0\" \"tiktoken~=0.4.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3c594c9-9528-40a4-80fb-022524cf6494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import cassio\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Cassandra\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd220f09-0e08-430f-9304-3b78733835af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ASTRA_DB_DATABASE_ID\" not in os.environ:\n",
    "    os.environ[\"ASTRA_DB_DATABASE_ID\"] = input(\"ASTRA_DB_DATABASE_ID = \")\n",
    "\n",
    "if \"ASTRA_DB_APPLICATION_TOKEN\" not in os.environ:\n",
    "    os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"] = getpass(\"ASTRA_DB_APPLICATION_TOKEN = \")\n",
    "\n",
    "if \"ASTRA_DB_KEYSPACE\" not in os.environ:\n",
    "    ks = input(\"(Optional) ASTRA_DB_KEYSPACE = \")\n",
    "    if ks:\n",
    "        os.environ[\"ASTRA_DB_KEYSPACE\"] = ks\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"OPENAI_API_KEY = \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae17194-c393-4751-9294-c15ff978139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A little bit of magic ...\n",
    "cassio.init(auto=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b65396e6-0bf3-4bd8-9a69-1fc87c6f987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b00005-4c70-4c87-a306-9cc5ba56252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Cassandra(\n",
    "    table_name=\"md_updates\",\n",
    "    embedding=embeddings,\n",
    "    session=None,  # these 'None' mean: use the global defaults set by cassio.init(...) earlier\n",
    "    keyspace=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0acbfb2a-9d97-4042-9783-6dbf6bf3e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us reset to run the demo (caution: don't run this on a prod table!)\n",
    "vector_store.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d8c72c-c3bf-45ee-be95-4b412e478496",
   "metadata": {},
   "source": [
    "### First we populate the vector store in the usual regular way\n",
    "\n",
    "Note we do both: (a) with explicit ID and (b) leaving the IDs to be determined by the store itself.\n",
    "\n",
    "Note that in LangChain the only way to provide IDs is to _not_ use `add_documents` and stay with `add_texts`, which has an `ids` optional parameter.\n",
    "\n",
    "Suggestion: even when there is no \"external\" way to fix the IDs (such as, the rows come from another database, etc), still try to make the IDs deterministic, such as the MD5 hash of the input text or something. This will make it easier to retrieve/update the correct row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1a6417b-8909-4a9f-b3fa-d74acf0fb569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['order_0', 'biology_0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_texts(\n",
    "    [\n",
    "        \"Two onigiri and a peach tea, please\",\n",
    "        \"Birds are dinosaurs, as a matter of fact the only living ones out there.\",\n",
    "    ],\n",
    "    ids=[\"order_0\", \"biology_0\"],\n",
    "    metadatas=[\n",
    "        {\n",
    "            \"type\": \"order\",\n",
    "            \"version\": \"v0\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"evolutionary_history\",\n",
    "            \"version\": \"v0\",\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817ec197-a50a-4500-b81e-514221251a09",
   "metadata": {},
   "source": [
    "Your store may also contain documents whose ID is autogenerated upon insertion. It will be up to you to retrieve this ID and use any of the methods above. Keep in mind that, if you want to stay within LangChain, the methods of the `Cassandra` vector-store class used to retrieve IDs along with the `Document`s are the following: `similarity_search_with_score_id` and `similarity_search_with_score_id_by_vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc67a0d3-fc65-4514-ae3d-4d3d73f79beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['703f9f30953a49e7be2d4444c993afbd']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc0 = Document(\n",
    "    page_content=\"Bohemian rhapsody\",\n",
    "    metadata={\"type\": \"song title\", \"version\": \"v0\", \"insertion_mode\": \"document, no ID passed\"},\n",
    ")\n",
    "vector_store.add_documents([doc0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef80bc1-b22d-4d97-8c5a-e5b434bf2ff3",
   "metadata": {},
   "source": [
    "## Option 3: Whole-row write + work at CassIO level + need to read text&vector beforehand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d10e832-932e-445f-9ef8-f22de606dd7f",
   "metadata": {},
   "source": [
    "Now you don't care at all about staying within the LangChain interface (which felt a little awkward for this task, didn't it?)\n",
    "\n",
    "Let's handle (a) the read to get the vector&text, and then (b) the subsequent write, all using CassIO's primitives.\n",
    "\n",
    "- Pro: no more baroque tricks to overcome LC's constraints.\n",
    "- Con: more care in possible changes to the code in the future (this is still jumping between abstractions after all).\n",
    "\n",
    "First you get the underlying CassIO table on which the Cassandra store is built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c888aa7c-f970-4031-9def-a65097828773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION: this line may need to be adapted to newer `Cassandra` releases in the near future\n",
    "cassio_table = vector_store.table.table  # Will become \"... = vector_store.table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43fb4007-1948-4631-8011-80c03f351959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_metadata_full_cassio(id, new_metadata):\n",
    "    # first we read...\n",
    "    # TODO handle no-row-found errors\n",
    "    row_from_table = cassio_table.get(row_id=id)\n",
    "    \n",
    "    # then we write:\n",
    "    new_row = {**row_from_table, **{\"metadata\": new_metadata}}\n",
    "    cassio_table.put(**new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f836760b-1255-439c-bb9d-8e949f1dcb88",
   "metadata": {},
   "source": [
    "#### Test with before-and-after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ad1575-1280-466c-a676-367255ee3dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Bohemian r...' MD = {'insertion_mode': 'document, no ID passed', 'type': 'song title', 'version': 'v0'}\n",
      "'Two onigir...' MD = {'type': 'order', 'version': 'v0'}\n",
      "'Birds are ...' MD = {'type': 'evolutionary_history', 'version': 'v0'}\n"
     ]
    }
   ],
   "source": [
    "for doc in vector_store.similarity_search(\"Songs\", k=5):\n",
    "    print(f\"'{doc.page_content[:10]}...' MD = {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16e56244-f261-4178-86a9-361939fe1c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_metadata_full_cassio(\"biology_0\", new_metadata={\"is_evolutionary_fact\": \"Y\", \"version\": \"v3\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e974423b-7957-4c33-b121-c631eb510a76",
   "metadata": {},
   "source": [
    "After:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2376689-2833-4fdc-8485-890bbd0adc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Bohemian r...' MD = {'insertion_mode': 'document, no ID passed', 'type': 'song title', 'version': 'v0'}\n",
      "'Two onigir...' MD = {'type': 'order', 'version': 'v0'}\n",
      "'Birds are ...' MD = {'is_evolutionary_fact': 'Y', 'version': 'v3'}\n"
     ]
    }
   ],
   "source": [
    "for doc in vector_store.similarity_search(\"Songs\", k=5):\n",
    "    print(f\"'{doc.page_content[:10]}...' MD = {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc532715-77a1-43a0-9832-af299eace7dc",
   "metadata": {},
   "source": [
    "## Option 4: Partial write + work at CassIO level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab9175-c510-4866-a9c9-cf9e179f888d",
   "metadata": {},
   "source": [
    "**Note**: partial writes (specifically, just ID + metadata in the write) map to CQL inserts. As such, the write succeeds even if the ID does not match any row in the table, resulting in the creation of an \"orphan\" row with no text and, crucially, no vector.\n",
    "\n",
    "As such, the row will never be found in ANN searches: functioning of the store is not disturbed by this. But there's the theoretical risk that as more and more such \"misfired\" writes pile up, the table will accumulate \"dark matter\" in the form of hard-to-spot useless stuff that could eventually become a problem. Just keep that in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea2cd41b-cba2-429e-ae28-f36527b76a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_metadata_partial_cassio(id, new_metadata):\n",
    "    new_row = {\"row_id\": id, \"metadata\": new_metadata}\n",
    "    cassio_table.put(**new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b404c6-f240-4aa2-a2cf-4852d3742f47",
   "metadata": {},
   "source": [
    "Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6390e35-cb5c-41c2-b850-857816a8612b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Birds are ...' MD = {'is_evolutionary_fact': 'Y', 'version': 'v3'}\n",
      "'Bohemian r...' MD = {'insertion_mode': 'document, no ID passed', 'type': 'song title', 'version': 'v0'}\n",
      "'Two onigir...' MD = {'type': 'order', 'version': 'v0'}\n"
     ]
    }
   ],
   "source": [
    "for doc in vector_store.similarity_search(\"Airplanes\", k=5):\n",
    "    print(f\"'{doc.page_content[:10]}...' MD = {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0a2cc1a-7a22-432a-8f36-8592ad587956",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_metadata_partial_cassio(\"order_0\", new_metadata={\"did_partial_update\": \"Oh, yeah\", \"version\": \"v4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d76977b-0dad-4cee-8a7b-d4439ea5f686",
   "metadata": {},
   "source": [
    "After:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "651d08b4-7ad3-4db0-98d6-29c78d0762e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Birds are ...' MD = {'is_evolutionary_fact': 'Y', 'version': 'v3'}\n",
      "'Bohemian r...' MD = {'insertion_mode': 'document, no ID passed', 'type': 'song title', 'version': 'v0'}\n",
      "'Two onigir...' MD = {'did_partial_update': 'Oh, yeah', 'version': 'v4'}\n"
     ]
    }
   ],
   "source": [
    "for doc in vector_store.similarity_search(\"Airplanes\", k=5):\n",
    "    print(f\"'{doc.page_content[:10]}...' MD = {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc630a6b-788f-435b-aeff-6cfbe9f3e5d0",
   "metadata": {},
   "source": [
    "## Option 5: Partial write + work at CassIO/LC level\n",
    "\n",
    "_Note: to be implemented, just outlining the idea here._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0872358-91f2-4786-9d4b-2c3f568ed6e3",
   "metadata": {},
   "source": [
    "The idea is simply to expose the spirit of Option 4 (a native CassIO-based `put` with just ID and metadata) into a method, specific to the `Cassandra` store (i.e. not dictated by the `VectorStore` interface).\n",
    "\n",
    "Something like\n",
    "\n",
    "```python\n",
    "my_store.update_metadata_by_id(id, new_metadata={...})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc7604d-5f6a-46ee-9f14-1e19a3b0b74c",
   "metadata": {},
   "source": [
    "Exposing this opens to the same risk as Option 4, namely \"orphan\" rows with no vector. Remember this is not a functional problem, just a possible cause of hard-to-spod \"debris\" on the table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6817703b-67e9-49c3-9103-d2a0b5f4857b",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb341cd-4fe7-482c-8633-a8a53c61b864",
   "metadata": {},
   "source": [
    "One way or the other, this shows how we can address \"single- or few-rows metadata update\".\n",
    "\n",
    "Suppose you have a list of, say, 500 IDs whose metadata should become `new_metadata`. You may wrap the above CQL insertions in concurrency to speed up things (up to 50-100 concurrency is generally not a problem at all with Cassandra / Astra DB writes).\n",
    "\n",
    "Remember if your update is not a whole-dictionary overwrite, rather something requiring read-before-write such as \"change k: v to k: v1, but keep all other fields unchanged\", there is no CassIO way other than a read-before-write.\n",
    "\n",
    "Now, of the various ways to _obtain_ the list of IDs for an update, one is interesting: CassIO offers a method to get all rows matching a given metadata condition, without an associated vector-query. This is something the `VectorStore` in LangChain does not have. Here is how you could implement the following task:\n",
    "\n",
    "> change all \"version\": \"v0\" rows to \"version\": \"v6\", keeping all other metadata fields untouched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ce142ae-4eb4-4259-80ef-4c0a66990b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iws0', 'iws1', 'iws2', 'iws3', 'iws4']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we insert another couple of \"v0\" rows just for the show:\n",
    "vector_store.add_texts(\n",
    "    [\n",
    "        \"First I was afraid\",\n",
    "        \"I was petrified\",\n",
    "        \"Kept thinking\",\n",
    "        \"I could never live\",\n",
    "        \"without you by my side\",\n",
    "    ],\n",
    "    ids=[\"iws0\", \"iws1\", \"iws2\", \"iws3\", \"iws4\"],\n",
    "    metadatas=[\n",
    "        {\"idx\": \"i0\", \"version\": \"v0\"},\n",
    "        {\"idx\": \"i1\", \"version\": \"v0\"},\n",
    "        {\"idx\": \"i2\", \"version\": \"v0\"},\n",
    "        {\"idx\": \"i3\", \"version\": \"v0\"},\n",
    "        {\"idx\": \"i4\", \"version\": \"v0\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa01245-e735-4c8f-b39a-45a4778d9395",
   "metadata": {},
   "source": [
    "Note that the `find_entries` requires a maximum number of entries. This stresses the fact that it should not be used for very, very large retrievals. Now, you could always re-run it after the update to make sure you get zero results ... (though you might want to ensure in most cases the first pass catches all results in the first place)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6672f92-fd12-4aaa-9971-39a4c6d62669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iws4', 'iws0', 'iws1', '703f9f30953a49e7be2d4444c993afbd', 'iws3', 'iws2']\n",
      "[{'idx': 'i4', 'version': 'v0'}, {'idx': 'i0', 'version': 'v0'}, {'idx': 'i1', 'version': 'v0'}, {'insertion_mode': 'document, no ID passed', 'type': 'song title', 'version': 'v0'}, {'idx': 'i3', 'version': 'v0'}, {'idx': 'i2', 'version': 'v0'}]\n"
     ]
    }
   ],
   "source": [
    "ids_and_md_for_v0 = [\n",
    "    (entry[\"row_id\"], entry[\"metadata\"])\n",
    "    for entry in cassio_table.find_entries(metadata={\"version\": \"v0\"}, n=100)\n",
    "]\n",
    "\n",
    "print([id for id, _ in ids_and_md_for_v0])\n",
    "\n",
    "print([md for _, md in ids_and_md_for_v0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7393488-7331-41ed-ab8a-85602b77dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_to_change, prev_md in ids_and_md_for_v0:\n",
    "    new_md = {**prev_md, **{\"version\": \"v6\"}}\n",
    "    update_metadata_partial_cassio(id_to_change, new_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277a595d-093e-40d1-a38f-6b8c796eb5e8",
   "metadata": {},
   "source": [
    "Now run an ANN query to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "687f7b63-4663-4389-b494-e437e6f80ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Kept think...' MD = {'idx': 'i2', 'version': 'v6'}\n",
      "'First I wa...' MD = {'idx': 'i0', 'version': 'v6'}\n",
      "'I was petr...' MD = {'idx': 'i1', 'version': 'v6'}\n",
      "'without yo...' MD = {'idx': 'i4', 'version': 'v6'}\n",
      "'I could ne...' MD = {'idx': 'i3', 'version': 'v6'}\n"
     ]
    }
   ],
   "source": [
    "for doc in vector_store.similarity_search(\"Feelings\", k=5, filter={\"version\": \"v6\"}):\n",
    "    print(f\"'{doc.page_content[:10]}...' MD = {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeaeeff-27ba-4209-b49d-de9dc91ebd38",
   "metadata": {},
   "source": [
    "### Concurrency\n",
    "\n",
    "If you have hundreds of such rows, concurrency might be a valuable speedup. Let's see it in action for \"v6 -> v7\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41206f0a-69d4-4c24-95fb-13ed3b264178",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_and_md_for_v6 = [\n",
    "    (entry[\"row_id\"], entry[\"metadata\"])\n",
    "    for entry in cassio_table.find_entries(metadata={\"version\": \"v6\"}, n=100)\n",
    "]\n",
    "\n",
    "def _upgrade_version(id_and_md):\n",
    "    id_to_change, prev_md = id_and_md\n",
    "    new_md = {**prev_md, **{\"version\": \"v7\"}}\n",
    "    update_metadata_partial_cassio(id_to_change, new_md)\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=50) as tpe:\n",
    "    _ = tpe.map(\n",
    "        _upgrade_version,\n",
    "        ids_and_md_for_v6,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af53893c-1cca-459e-8bb7-a91bc2621c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Kept think...' MD = {'idx': 'i2', 'version': 'v7'}\n",
      "'First I wa...' MD = {'idx': 'i0', 'version': 'v7'}\n",
      "'I was petr...' MD = {'idx': 'i1', 'version': 'v7'}\n",
      "'without yo...' MD = {'idx': 'i4', 'version': 'v7'}\n",
      "'I could ne...' MD = {'idx': 'i3', 'version': 'v7'}\n",
      "'Bohemian r...' MD = {'insertion_mode': 'document, no ID passed', 'type': 'song title', 'version': 'v7'}\n"
     ]
    }
   ],
   "source": [
    "for doc in vector_store.similarity_search(\"Feelings, again\", k=10, filter={\"version\": \"v7\"}):\n",
    "    print(f\"'{doc.page_content[:10]}...' MD = {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f527ff-df04-4b08-a298-b3ef78e39675",
   "metadata": {},
   "source": [
    "# \"Try to stay in LC\" section\n",
    "\n",
    "_Mostly kept only for historical relevance_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9146cf1a-1b08-47ad-be89-365efed34194",
   "metadata": {},
   "source": [
    "## Option 1: Whole-row write + stay (mostly) on LC + know whole row already\n",
    "\n",
    "_Note: this option likely to be disregarded as more effort than advantage._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d3c8cb-ce1c-4e10-934a-a79fa9483818",
   "metadata": {},
   "source": [
    "The easiest scenario is, you know the whole row already (in particular ID, vector, text) and want to update it with a wholly new metadata dictionary.\n",
    "\n",
    "You want to stay within the LC abstraction, so ... you would be calling the store's `add_texts` method, except you don't want the store to use the actual embedding service and spend time and money repeating the embedding!\n",
    "\n",
    "To overcome this (LangChain) limitation, here's a trick: prepare a \"twin\" VectorStore, based on the same Cassandra table, but which uses a custom \"Embeddings\" that actually knows of the vectors you tell it to use for any given text!\n",
    "\n",
    "So you will first create a special Embedding class to convey the vectors you want, then you will create a twin vector store. Look:\n",
    "\n",
    "_Note: some imports below are from `langchain_core`. This is because of recent major refactoring in LangChain (a split in \"core\" vs \"the rest\"). If you're not on the latest versions, check the imports below - nothing else should require changes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c5fa2e-4dd6-443a-b153-0ed595c50012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "from langchain_core.embeddings import Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5216a8-307f-405f-8479-ffbf8b525148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdaterEmbeddings(Embeddings):\n",
    "\n",
    "    def __init__(self, dimension: int) -> None:\n",
    "        self.dimension = dimension\n",
    "        # TODO: make this into a (large-ish) LRU cache to control memory growth\n",
    "        # input text -> its embedding\n",
    "        self.vector_cache: Dict[str, List[float]] = {}\n",
    "\n",
    "    def prime_for_vector(self, text: str, vector: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Locally cache a text->vector association for subsequent usage.\n",
    "        This is to be called right before add_texts on the associated VectorStore\n",
    "        \"\"\"\n",
    "        self.vector_cache[text] = vector\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        # TODO: can be optimized with well-crafted concurrency later...\n",
    "        return [self.embed_query(txt) for txt in texts]\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        if text not in self.vector_cache:\n",
    "            # We need to execute in this case as well to satisfy the \"dimension-measuring moot call\"\n",
    "            print(f\"** Non-primed text requested. Returning null vector (requested: '{text}') **\")\n",
    "            # as long as you use COS, this would raise an error if inadvertently\n",
    "            # going all the way to being written. To be clear, this is to our advantage!\n",
    "            return [0.0] * self.dimension\n",
    "        else:\n",
    "            return self.vector_cache[text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be6fc41-fa3f-4023-ba96-400930b44d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_updater_embeddings = UpdaterEmbeddings(dimension=1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506afcf-1cf1-4f1c-94c9-aeadb49e0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_updater_vector_store = Cassandra(\n",
    "    table_name=\"md_updates\",\n",
    "    embedding=my_updater_embeddings,\n",
    "    session=None,\n",
    "    keyspace=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca35b36-c22a-4912-b268-d044d397a8b4",
   "metadata": {},
   "source": [
    "### Running an update\n",
    "\n",
    "Below we wrap the behaviour we want into a simple function - it can be integrated better, e.g. by subclassing `Cassandra` or similar.\n",
    "\n",
    "Also it may be extended for clever bulk updates (concurrent reads, etc) as this prototype does entries one at a time only.\n",
    "\n",
    "Now, however, the immediate goal here is to show the basic mechanism at work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de805fae-4037-4b76-b023-5428d4c743d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_metadata_by_full_row(id, row_text, row_vector, row_metadata, updater_store=my_updater_vector_store):\n",
    "    # step 1: teach the trick-Embeddings to associate the known vector to the given text\n",
    "    # (this is a funny step, to circumvent LangChain's interface limitations)\n",
    "    updater_store.embedding.prime_for_vector(text=row_text, vector=row_vector)\n",
    "    # step 2: call add_texts and let the vector be retrieved from the trick-Embedding and saved with the rest\n",
    "    updater_store.add_texts(texts=[row_text], metadatas=[row_metadata], ids=[id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2289ae-e863-4dd3-8ab9-cc9379e0e1ea",
   "metadata": {},
   "source": [
    "Before-and-after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bcc729-0c0a-44af-9f0c-41a38e775d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id_to_update = \"biology_0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b37c7e7-c446-4d5f-afa3-6fd72d9c8acc",
   "metadata": {},
   "source": [
    "Let's say you \"magically\" know the vector and the text for a given ID. Here we cheat (more on that in the next section):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505c3b2-dd31-4a94-95cc-be59c96c0f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pretend somehow we have the full row we want to update\n",
    "# CAUTION: this line may need to be adapted to newer `Cassandra` releases in the near future\n",
    "bio_row = vector_store.table.table.get(row_id=doc_id_to_update)  # will become: \"... = vector_store.table.get(...\"\n",
    "\n",
    "bio_vector = bio_row[\"vector\"]\n",
    "bio_text = bio_row[\"body_blob\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3836e361-3c9f-4adc-b423-25954b74acfb",
   "metadata": {},
   "source": [
    "_Note that ordinary usage of the store (i.e. the ANN searches below) _must_ go through the original `vector_store`, since the updater has no real way to compute new embeddings!_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a54a0b-4a01-4720-906b-facb983b68c2",
   "metadata": {},
   "source": [
    "Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd56808-8ba3-4fcd-9781-d6e9848a1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in vector_store.similarity_search(\"Query text\", k=5):\n",
    "    print(f\"'{doc.page_content[:10]}...' MD = {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373a41c-4b45-4bb7-8128-8d24c8ea0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_metadata_by_full_row(\n",
    "    id=doc_id_to_update,\n",
    "    row_text=bio_text,\n",
    "    row_vector=bio_vector,\n",
    "    row_metadata={\"version\": \"v1\", \"type\": \"dinosaurs\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950cb28-a96a-4411-932a-f9c2f89d9ef1",
   "metadata": {},
   "source": [
    "After:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16a565-79bf-4bb6-825e-f789860f545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in vector_store.similarity_search(\"Query text\", k=5):\n",
    "    print(f\"'{doc.page_content[:10]}...' MD = {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c86b4-fd9b-4f7e-942d-1aace65c4799",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1. the above effectively can be used to change anything: text and/or vector and/or metadata (use at your own risk)\n",
    "2. Most importantly ... we cheated and read the whole row from DB. There is no way to do that within the LC abstraction. So let's bake the read-before-write into the metadata update procedure itself: indeed the inputs will generally be ID and metadata alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f5c42d-2d6e-40e7-bf13-20639d9f7b8c",
   "metadata": {},
   "source": [
    "## Option 2: Whole-row write + stay (mostly) on LC + need to read text&vector beforehand\n",
    "\n",
    "_Note: this option likely to be disregarded as more effort than advantage._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a414a77-d3f8-44f0-a3c7-8a799e879eb9",
   "metadata": {},
   "source": [
    "This is simply wrapping the read, required to get vector and text, into the main \"update metadata\" procedure.\n",
    "\n",
    "Now, while the write stays at the LC level (at the cost of coding the special \"embedding function\" class you've seen and of instantiating the \"updater\" twin of the store), the _read_ must inevitably break out of LangChain. LangChain's `VectorStore` never exposes a vector directly to users, there's no way.\n",
    "\n",
    "We'll have to descend to the CassIO abstraction level for the read.\n",
    "\n",
    "In practice, we just add the read as the first part of the update routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec2d64c-c98f-4a76-8cc6-20ec530b2859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_metadata_by_id(id, new_metadata, updater_store=my_updater_vector_store):\n",
    "    # step 1: retrieve the rest of the row we need\n",
    "    # TODO: handle row-not-found errors and the like\n",
    "\n",
    "    # CAUTION: this line may need to be adapted to newer `Cassandra` releases in the near future\n",
    "    cassio_table = updater_store.table.table  # will become: \"... = updater_store.table\"\n",
    "\n",
    "    doc_from_table = cassio_table.get(row_id=id)\n",
    "    row_text = doc_from_table[\"body_blob\"]\n",
    "    row_vector = doc_from_table[\"vector\"]\n",
    "    \n",
    "    # step 2: back to \"update by full row\" now:\n",
    "    update_metadata_by_full_row(id=id, row_text=row_text, row_vector=row_vector, row_metadata=new_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f4b772-8c84-4d0c-9aee-fe7a0c669580",
   "metadata": {},
   "source": [
    "Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e947f-6754-464d-ba4f-bb15922d6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in vector_store.similarity_search(\"Animals\", k=5):\n",
    "    print(f\"'{doc.page_content[:10]}...' MD = {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b91bec-c192-4c0f-bdc0-808c14db29de",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_metadata_by_id(\"order_0\", {\"food_item\": \"onigiri\", \"version\": \"v2\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b99cc2-60e6-423c-be8f-4701ce51965e",
   "metadata": {},
   "source": [
    "After:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e701f9-5689-4896-bda0-5c4e630ff0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in vector_store.similarity_search(\"Animals\", k=5):\n",
    "    print(f\"'{doc.page_content[:10]}...' MD = {doc.metadata}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
